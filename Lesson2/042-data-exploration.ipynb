{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<p>\n",
    "  <b>AI Lab: Deep Learning for Computer Vision</b><br>\n",
    "  <b><a href=\"https://www.wqu.edu/\">WorldQuant University</a></b>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "  <p>\n",
    "    <center><b>Usage Guidelines</b></center>\n",
    "  </p>\n",
    "  <p>\n",
    "    This file is licensed under <a href=\"https://creativecommons.org/licenses/by-nc-nd/4.0/\">Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International</a>.\n",
    "  </p>\n",
    "  <p>\n",
    "    You <b>can</b>:\n",
    "    <ul>\n",
    "      <li><span style=\"color: green\">✓</span> Download this file</li>\n",
    "      <li><span style=\"color: green\">✓</span> Post this file in public repositories</li>\n",
    "    </ul>\n",
    "    You <b>must always</b>:\n",
    "    <ul>\n",
    "      <li><span style=\"color: green\">✓</span> Give credit to <a href=\"https://www.wqu.edu/\">WorldQuant University</a> for the creation of this file</li>\n",
    "      <li><span style=\"color: green\">✓</span> Provide a <a href=\"https://creativecommons.org/licenses/by-nc-nd/4.0/\">link to the license</a></li>\n",
    "    </ul>\n",
    "    You <b>cannot</b>:\n",
    "    <ul>\n",
    "      <li><span style=\"color: red\">✗</span> Create derivatives or adaptations of this file</li>\n",
    "      <li><span style=\"color: red\">✗</span> Use this file for commercial purposes</li>\n",
    "    </ul>\n",
    "  </p>\n",
    "  <p>\n",
    "    Failure to follow these guidelines is a violation of your terms of service and could lead to your expulsion from WorldQuant University and the revocation your certificate.\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first import the libraries we'll be using. We're using the same libraries we used in previous projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pytubefix\n",
    "import torch\n",
    "import torchvision\n",
    "from IPython.display import Video\n",
    "from pytubefix import YouTube\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also print out library versions as well as the Python version. This makes our analysis reproducible for anyone who wants to review or reuse our work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"torch version : \", torch.__version__)\n",
    "print(\"pytube version : \", pytubefix.__version__)\n",
    "print(\"torchvision version : \", torchvision.__version__)\n",
    "print(\"cv2 version : \", cv2.__version__)\n",
    "\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching YouTube Video Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we'll use a video of an interview with an Indian Olympic boxer [Mary Kom](https://en.wikipedia.org/wiki/Mary_Kom). She's a legendary athlete with many achievements. Among others, she's the only boxer to ever win eight World Championship medals.\n",
    "\n",
    "We'll load the video of her interview from YouTube. We want to put the video file in directory `\"data\"` which should be in the `\"project4\"` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.2.1:** Create a variable for the video directory using `pathlib` syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_dir = Path(\"project4\")\n",
    "data_dir = \"data\"\n",
    "video_dir = ...\n",
    "\n",
    "print(video_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Next we'll need to specify the URL of the YouTube video and download the video. We decided to save the video under file name `video_name = \"mary_kom.mp4\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_name = \"mary_kom.mp4\"\n",
    "video_url = \"https://www.youtube.com/watch?v=XScnCdyVbIU\"\n",
    "yt = YouTube(video_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because downloading from YouTube doesn't always work, we wrapped the code in a `try/except` block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.2.2:** Fill in the missing code in the `else` part of the `try/except` block below. If grabbing the YouTube stream worked, we want to download the video to directory `video_dir` using file name `video_name`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>Changes with respect to the video</b></p>\n",
    "<p>The instructor in the video is downloading the video directly from YouTube. We've since made changes to include the video as part of the project and spare you the download time.</p>\n",
    "    <p>We've left the activity as a placeholder but you can skip it altogether.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The video is already available in the following location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l project4/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.2.3:** Create a variable for the video file path using `pathlib` syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following variables you've already defined will be helpful\n",
    "print(video_dir)\n",
    "print(video_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video = ...\n",
    "\n",
    "print(input_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a peak of the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the video\n",
    "Video(input_video, width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The video is quite long and we'll only need a small portion of it. In a previous project, we \n",
    "truncated a video with `ffmpeg`, a command line tool for video and audio editing. This time, let's create a Python function that can cut down the video!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.2.4:** Fill in the missing code that defines the signature of the `cut_video` function. By looking at the function's doc string, you can see what the input parameters should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_video(..., ..., ..., ...):\n",
    "    \"\"\"\n",
    "    Cuts a portion of the video.\n",
    "\n",
    "    :parameter input_file: Path to the input video file.\n",
    "    :parameter output_file: Path to the output video file.\n",
    "    :parameter start_time: Start time of the cut in seconds or in `HH:MM:SS` format.\n",
    "    :parameter duration: Duration of the cut in seconds or in `HH:MM:SS` format.\n",
    "    \"\"\"\n",
    "    command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-ss\",\n",
    "        str(start_time),\n",
    "        \"-i\",\n",
    "        input_file,\n",
    "        \"-t\",\n",
    "        str(duration),\n",
    "        \"-c\",\n",
    "        \"copy\",\n",
    "        output_file,\n",
    "    ]\n",
    "    subprocess.run(command)\n",
    "\n",
    "\n",
    "cut_video?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we use this function, we should first prepare the output video path where we want to save the shortened video (`output_file` parameter we need to pass to the function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.2.5:** Create a variable for the output video file path using `pathlib` syntax. Let's call the file `\"output.mp4\"`. It should be in the same directory as our input video file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_video_name = \"output.mp4\"\n",
    "\n",
    "output_video = ...\n",
    "\n",
    "print(output_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.2.6:** Call the `cut_video` function using the `input_video` and `output_video` variables you defined in the previous tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = \"00:00:00\"  # Start at 00 seconds\n",
    "duration = \"00:01:00\"  # Cut 1 minute\n",
    "\n",
    "# Call cut_video function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done! We should be able to display this shortened one minute video we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the video\n",
    "Video(output_video, width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring and Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's learn a bit more about our video data. We're curious about things like the frame rate, total frame count, and frame shape. To get this information, we'll use the `opencv-python` library just like in the previous project (`cv2` which we imported at the top of the notebook).\n",
    "\n",
    "The first step is to create a video capture using `cv2.VideoCapture` and pass in the path to our video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.2.7:** Create a video capture for the one minute video we're working with. The rest of the code computes the frame rate and total frame count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = ...\n",
    "\n",
    "if not video_capture.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "else:\n",
    "    frame_rate = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"Frame rate: {frame_rate}\")\n",
    "    print(f\"Total number of frames: {frame_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's display the first frame. We can fetch the first frame of our video capture by calling the `read()` method on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.2.8:** Use the video capture variable you defined in the previous task and fetch the first frame. The rest of the code will display the frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, first_frame = ...\n",
    "\n",
    "if ret:\n",
    "    plt.imshow(cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"First Frame\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Error: Could not read frame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.2.9:** Get the shape of the frame and the number of channels by calling the `shape` attribute on the `first_frame` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width, channel = ...\n",
    "\n",
    "print(\"frames height : \", height)\n",
    "print(\"frames width : \", width)\n",
    "print(\"frames channel : \", channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing we need to do is extract the individual frames from the video. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.2.10:** Create a directory path for the extracted frames using the `pathlib` syntax. This path should be a directory called `extracted_frames` which should be in `video_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_dir = ...\n",
    "\n",
    "frames_dir.mkdir(exist_ok=True)\n",
    "print(frames_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.2.11:** Fill in the missing code below that saves every fifth frame from the video. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = frame_rate * 0.20  # Extract every fifth frame from the video\n",
    "frame_count = 0\n",
    "\n",
    "print(\"Start extracting individual frames...\")\n",
    "while True:\n",
    "    # read next frame from the video_capture\n",
    "    ret, frame = ...\n",
    "    if not ret:\n",
    "        print(\"Finished!\")\n",
    "        break  # Break the loop if there are no more frames\n",
    "\n",
    "    # Save frames at every 'interval' frames\n",
    "    if frame_count % ... == 0:\n",
    "        frame_path = frames_dir / f\"frame_{frame_count}.jpg\"\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "video_capture.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.2.12:** Compute the number of frames we've extracted by using `iterdir()` method on the `frames_dir` path. That'll give you a generator that you need to covert to `list` before using`len`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_extraced_frames = ...\n",
    "\n",
    "print(f\"We saved {n_extraced_frames} frames.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude this lesson, let's display some sample frames that we extracted. The function `display_sample_images` below that'll display a grid of sample frames is the same as the one we used in the previous project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.2.13:** Fill in the missing code in `display_sample_images` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sample_images(dir_path, sample=5):\n",
    "    image_list = []\n",
    "    images = sorted(dir_path.iterdir())\n",
    "    if images:\n",
    "        sample_images = images[:sample]\n",
    "        for sample_image in sample_images:\n",
    "            image = read_image(str(sample_image))\n",
    "            \n",
    "            # Define resizing transformation that resizes to 240 x 240\n",
    "            resize_transform = ...\n",
    "            # Resize image by using `resize_transform`\n",
    "            image = ...\n",
    "            image_list.append(image)\n",
    "    grid = make_grid(image_list, nrow=5)\n",
    "    image = to_pil_image(grid)\n",
    "    return image\n",
    "\n",
    "\n",
    "display_sample_images?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.2.14:** Use `display_sample_images` function to display 20 of the frames that we extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function `display_sample_images` on `frames_dir`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "This file &#169; 2024 by [WorldQuant University](https://www.wqu.edu/) is licensed under [CC BY-NC-ND 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
